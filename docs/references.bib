% Encoding: UTF-8
% Try to keep this list in alphabetical order based on citing name

@article{breiman2001random,
  title     = {Random forests},
  author    = {Breiman, Leo},
  journal   = {Machine learning},
  volume    = {45},
  pages     = {5--32},
  year      = {2001},
  publisher = {Springer}
}

@article{Li2019manifold,
  title   = {Manifold Oblique Random Forests: Towards Closing the Gap on Convolutional Deep Networks},
  author  = {Li, Adam and Perry, Ronan and Huynh, Chester and Tomita, Tyler M and Mehta, Ronak and Arroyo, Jesus and Patsolic, Jesse and Falk, Benjamin and Vogelstein, Joshua T},
  journal = {arXiv preprint arXiv:1909.11799},
  year    = {2019}
}

@inproceedings{Meghana2019_geodesicrf,
  author    = {Madhyastha, Meghana and Li, Percy and Browne, James and Strnadova-Neeley, Veronika and Priebe, Carey E. and Burns, Randal and Vogelstein, Joshua T.},
  title     = {Geodesic Forests},
  year      = {2020},
  isbn      = {9781450379984},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3394486.3403094},
  doi       = {10.1145/3394486.3403094},
  abstract  = {Together with the curse of dimensionality, nonlinear dependencies in large data sets persist as major challenges in data mining tasks. A reliable way to accurately preserve nonlinear structure is to compute geodesic distances between data points. Manifold learning methods, such as Isomap, aim to preserve geodesic distances in a Riemannian manifold. However, as manifold learning algorithms operate on the ambient dimensionality of the data, the essential step of geodesic distance computation is sensitive to high-dimensional noise. Therefore, a direct application of these algorithms to high-dimensional, noisy data often yields unsatisfactory results and does not accurately capture nonlinear structure.We propose an unsupervised random forest approach called geodesic forests (GF) to geodesic distance estimation in linear and nonlinear manifolds with noise. GF operates on low-dimensional sparse linear combinations of features, rather than the full observed dimensionality. To choose the optimal split in a computationally efficient fashion, we developed Fast-BIC, a fast Bayesian Information Criterion statistic for Gaussian mixture models.We additionally propose geodesic precision and geodesic recall as novel evaluation metrics that quantify how well the geodesic distances of a latent manifold are preserved. Empirical results on simulated and real data demonstrate that GF is robust to high-dimensional noise, whereas other methods, such as Isomap, UMAP, and FLANN, quickly deteriorate in such settings. Notably, GF is able to estimate geodesic distances better than other approaches on a real connectome dataset.},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},
  pages     = {513â€“-523},
  numpages  = {11},
  keywords  = {random forest, noisy data, unsupervised, manifold learning},
  location  = {Virtual Event, CA, USA},
  series    = {KDD '20}
}

@article{TomitaSPORF2020,
  author  = {Tyler M. Tomita and James Browne and Cencheng Shen and Jaewon Chung and Jesse L. Patsolic and Benjamin Falk and Carey E. Priebe and Jason Yim and Randal Burns and Mauro Maggioni and Joshua T. Vogelstein},
  title   = {Sparse Projection Oblique Randomer Forests},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {104},
  pages   = {1--39},
  url     = {http://jmlr.org/papers/v21/18-664.html}
}