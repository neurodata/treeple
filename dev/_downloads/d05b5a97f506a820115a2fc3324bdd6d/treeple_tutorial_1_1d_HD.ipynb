{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Calculating Hellinger Distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nfrom treeple.datasets import make_trunk_classification\nfrom treeple.ensemble import HonestForestClassifier\nfrom treeple.stats import build_oob_forest\n\nsns.set(color_codes=True, style=\"white\", context=\"talk\", font_scale=1.5)\nPALETTE = sns.color_palette(\"Set1\")\nsns.set_palette(PALETTE[1:5] + PALETTE[6:], n_colors=9)\nsns.set_style(\"white\", {\"axes.edgecolor\": \"#dddddd\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hellinger Distance\n\nHellinger distance quantifies the similarity between the two posterior\nprobability distributions (class zero and class one).\n\n\\begin{align}H(\\eta(X), 1-\\eta(X)) = \\frac{1}{\\sqrt{2}} \\; \\bigl\\|\\sqrt{\\eta(X)} - \\sqrt{1-\\eta(X)} \\bigr\\|_2\\end{align}\n\nWith a binary class simulation as an example, this tutorial will show\nhow to use ``treeple`` to calculate the statistic.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a simulation with two gaussians\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create a binary class simulation with two gaussians\n# 500 samples for each class, class zero is standard\n# gaussian, and class one has a mean at one\nX, y = make_trunk_classification(\n    n_samples=1000,\n    n_dim=1,\n    mu_0=0,\n    mu_1=1,\n    n_informative=1,\n    seed=1,\n)\n\n\nfig, ax = plt.subplots(figsize=(6, 6))\nfig.tight_layout()\nax.tick_params(labelsize=15)\n\n# histogram plot the samples\nax.hist(X[:500], bins=50, alpha=0.6, color=PALETTE[1], label=\"negative\")\nax.hist(X[500:], bins=50, alpha=0.3, color=PALETTE[0], label=\"positive\")\nax.set_xlabel(\"Variable One\", fontsize=15)\nax.set_ylabel(\"Likelihood\", fontsize=15)\nplt.legend(frameon=False, fontsize=15)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# initialize the forest with 100 trees\nest = HonestForestClassifier(\n    n_estimators=100,\n    max_samples=1.6,\n    max_features=0.3,\n    bootstrap=True,\n    stratify=True,\n    random_state=1,\n)\n\n# fit the model and obtain the tree posteriors\n_, observe_proba = build_oob_forest(est, X, y)\n\n# generate forest posteriors for the two classes\nobserve_proba = np.nanmean(observe_proba, axis=0)\n\n\nfig, ax = plt.subplots(figsize=(6, 6))\nfig.tight_layout()\nax.tick_params(labelsize=15)\n\n# histogram plot the posterior probabilities for class one\nax.hist(observe_proba[:500][:, 1], bins=50, alpha=0.6, color=PALETTE[1], label=\"negative\")\nax.hist(observe_proba[500:][:, 1], bins=50, alpha=0.3, color=PALETTE[0], label=\"positive\")\nax.set_ylabel(\"# of Samples\", fontsize=15)\nax.set_xlabel(\"Class One Posterior\", fontsize=15)\nplt.legend(frameon=False, fontsize=15)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate the statistic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def Calculate_hd(y_pred_proba) -> float:\n    return np.sqrt(\n        np.sum((np.sqrt(y_pred_proba[:, 1]) - np.sqrt(y_pred_proba[:, 0])) ** 2)\n    ) / np.sqrt(2)\n\n\nhd = Calculate_hd(observe_proba)\nprint(\"Hellinger distance =\", round(hd, 2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}