{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demonstrate and visualize a multi-view projection matrix for an axis-aligned tree\n\nThis example shows how multi-view projection matrices are generated for a decision tree,\nspecifically the :class:`treeple.tree.MultiViewDecisionTreeClassifier`.\n\nMulti-view projection matrices operate under the assumption that the input ``X`` array\nconsists of multiple feature-sets that are groups of features important for predicting\n``y``.\n\nFor details on how to use the hyperparameters related to the multi-view, see\n:class:`treeple.tree.MultiViewDecisionTreeClassifier`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# import modules\n# .. note:: We use a private Cython module here to demonstrate what the patches\n#           look like. This is not part of the public API. The Cython module used\n#           is just a Python wrapper for the underlying Cython code and is not the\n#           same as the Cython splitter used in the actual implementation.\n#           To use the actual splitter, one should use the public API for the\n#           relevant tree/forests class.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.cm import ScalarMappable\nfrom matplotlib.colors import ListedColormap\n\nfrom treeple._lib.sklearn.tree._criterion import Gini\nfrom treeple.tree._oblique_splitter import MultiViewSplitterTester\n\ncriterion = Gini(1, np.array((0, 1)))\nmax_features = 5\nmin_samples_leaf = 1\nmin_weight_leaf = 0.0\nrandom_state = np.random.RandomState(10)\n\n# we \"simulate\" three feature sets, with 3, 2 and 4 features respectively\nfeature_set_ends = np.array([3, 5, 9], dtype=np.intp)\nn_feature_sets = len(feature_set_ends)\n\nmax_features_per_set_ = None\nfeature_combinations = 1\nmonotonic_cst = None\nmissing_value_feature_mask = None\n\n# initialize some dummy data\nX = np.repeat(np.arange(feature_set_ends[-1]).astype(np.float32), 5).reshape(5, -1)\ny = np.array([0, 0, 0, 1, 1]).reshape(-1, 1).astype(np.float64)\nsample_weight = np.ones(5)\n\nprint(\"The shape of our dataset is: \", X.shape, y.shape, sample_weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the multi-view splitter\nThe multi-view splitter is a Cython class that is initialized internally\nin treeple. However, we expose a Python tester object to demonstrate\nhow the splitter works in practice.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Do not use this interface directly in practice.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splitter = MultiViewSplitterTester(\n    criterion,\n    max_features,\n    min_samples_leaf,\n    min_weight_leaf,\n    random_state,\n    monotonic_cst,\n    feature_combinations,\n    feature_set_ends,\n    n_feature_sets,\n    max_features_per_set_,\n)\nsplitter.init_test(X, y, sample_weight, missing_value_feature_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample the projection matrix\nThe projection matrix is sampled by the splitter. The projection\nmatrix is a (max_features, n_features) matrix that selects which features of ``X``\nto define candidate split dimensions. The multi-view\nsplitter's projection matrix though samples from multiple feature sets,\nwhich are aligned contiguously over the columns of ``X``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "projection_matrix = splitter.sample_projection_matrix_py()\nprint(projection_matrix)\n\ncmap = ListedColormap([\"white\", \"green\"][:n_feature_sets])\n\n# Create a heatmap to visualize the indices\nfig, ax = plt.subplots(figsize=(6, 6))\n\nax.imshow(\n    projection_matrix, cmap=cmap, aspect=feature_set_ends[-1] / max_features, interpolation=\"none\"\n)\nax.axvline(feature_set_ends[0] - 0.5, color=\"black\", linewidth=1, label=\"Feature Sets\")\nfor iend in feature_set_ends[1:]:\n    ax.axvline(iend - 0.5, color=\"black\", linewidth=1)\n\nax.set(title=\"Sampled Projection Matrix\", xlabel=\"Feature Index\", ylabel=\"Projection Vector Index\")\nax.set_xticks(np.arange(feature_set_ends[-1]))\nax.set_yticks(np.arange(max_features))\nax.set_yticklabels(np.arange(max_features, dtype=int) + 1)\nax.set_xticklabels(np.arange(feature_set_ends[-1], dtype=int) + 1)\nax.legend()\n\n# Create a mappable object\nsm = ScalarMappable(cmap=cmap)\nsm.set_array([])  # You can set an empty array or values here\n\n# Create a color bar with labels for each feature set\ncolorbar = fig.colorbar(sm, ax=ax, ticks=[0.25, 0.75], format=\"%d\")\ncolorbar.set_label(\"Projection Weight (I.e. Sampled Feature From a Feature Set)\")\ncolorbar.ax.set_yticklabels([\"0\", \"1\"])\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling split candidates scaled to each feature-set dimensionality\nIn the previous setup, we do not specify the ``max_features_per_set`` parameter.\nThis results in the splitter sampling from all features uniformly. However, we can\nalso specify ``max_features_per_set`` to sample from each feature set with a different\nscaling factor. For example, if we want to sample from the first feature set three times\nmore than the second feature set, we can specify ``max_features_per_set`` as follows:\n``max_features_per_set = [3, 1]``. This will sample from the first feature set three times\nand the second feature set once.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In practice, this is controlled by the ``apply_max_features_per_feature_set`` parameter\n  in :class:`treeple.tree.MultiViewDecisionTreeClassifier`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_features_per_set_ = np.array([1, 2, 3], dtype=int)\nmax_features = np.sum(max_features_per_set_)\n\nsplitter = MultiViewSplitterTester(\n    criterion,\n    max_features,\n    min_samples_leaf,\n    min_weight_leaf,\n    random_state,\n    monotonic_cst,\n    feature_combinations,\n    feature_set_ends,\n    n_feature_sets,\n    max_features_per_set_,\n)\nsplitter.init_test(X, y, sample_weight, missing_value_feature_mask)\n\n# Here, we sampled 1 feature from the first feature set, 2 features from the second feature set\n# and 3 features from the third feature set.\nprojection_matrix = splitter.sample_projection_matrix_py()\nprint(projection_matrix)\n\n# Create a heatmap to visualize the indices\nfig, ax = plt.subplots(figsize=(6, 6))\n\nax.imshow(\n    projection_matrix, cmap=cmap, aspect=feature_set_ends[-1] / max_features, interpolation=\"none\"\n)\nax.axvline(feature_set_ends[0] - 0.5, color=\"black\", linewidth=1, label=\"Feature Sets\")\nfor iend in feature_set_ends[1:]:\n    ax.axvline(iend - 0.5, color=\"black\", linewidth=1)\n\nax.set(title=\"Sampled Projection Matrix\", xlabel=\"Feature Index\", ylabel=\"Projection Vector Index\")\nax.set_xticks(np.arange(feature_set_ends[-1]))\nax.set_yticks(np.arange(max_features))\nax.set_yticklabels(np.arange(max_features, dtype=int) + 1)\nax.set_xticklabels(np.arange(feature_set_ends[-1], dtype=int) + 1)\nax.legend()\n\n# Create a mappable object\nsm = ScalarMappable(cmap=cmap)\nsm.set_array([])  # You can set an empty array or values here\n\n# Create a color bar with labels for each feature set\ncolorbar = fig.colorbar(sm, ax=ax, ticks=[0.25, 0.75], format=\"%d\")\ncolorbar.set_label(\"Projection Weight (I.e. Sampled Feature From a Feature Set)\")\ncolorbar.ax.set_yticklabels([\"0\", \"1\"])\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\nAs we can see, the multi-view splitter samples split candidates across the feature sets.\nIn contrast, the normal splitter in :class:`sklearn.tree.DecisionTreeClassifier` samples\nrandomly across all ``n_features`` features because it is not aware of the multi-view structure.\nThis is the key difference between the two splitters.\n\nFor an example of using the multi-view splitter in practice on simulated data, see\n`sphx_glr_auto_examples_multiview_plot_multiview_dtc.py`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}