{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Quantile prediction intervals with Random Forest Regressor\n\nAn example of how to generate quantile prediction intervals with\nRandom Forest Regressor class on the California Housing dataset.\nThe plot compares the conditional median with the quantile prediction intervals, i.e. prediction at\nquantile parameter being 0.025, 0.5 and 0.975. This allows us to generate predictions at 95%\nintervals with upper and lower bounds.\n\nThis example was heavily inspired by [quantile-forest](https://github.com/zillow/quantile-forest)\npackage. See their package [here](https://zillow.github.io/quantile-forest/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.ticker import FuncFormatter\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.utils.validation import check_random_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quantile Prediction Function\n\nThe following function is used to generate quantile predictions using the samples\nthat fall into the same leaf node. We collect the corresponding values for each sample and\nuse those as the bases for making quantile predictions.\nThe function takes the following arguments:\n1. estimator :class:`~sklearn.ensemble.RandomForestRegressor` estimator or any other variations.\n2. X_train : training data to be used to train the tree.\n3. X_test : testing data to be used to predict the quantiles.\n4. y_train : training labels to be used to train the tree and to make quantile predictions.\n5. quantiles : list of quantiles to be predicted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# function to calculate the quantile predictions\ndef get_quantile_prediction(estimator, X_train, X_test, y_train, quantiles=[0.5]):\n    estimator.fit(X_train, y_train)\n    # get the leaf nodes that each sample fell into\n    leaf_ids = estimator.apply(X_train)\n    # create a list of dictionary that maps node to samples that fell into it\n    # for each tree\n    node_to_indices = []\n    for tree in range(leaf_ids.shape[1]):\n        d = defaultdict(list)\n        for id, leaf in enumerate(leaf_ids[:, tree]):\n            d[leaf].append(id)\n        node_to_indices.append(d)\n    # drop the X_test to the trained tree and\n    # get the indices of leaf nodes that fall into it\n    leaf_ids_test = estimator.apply(X_test)\n    # for each samples, collect the indices of the samples that fell into\n    # the same leaf node for each tree\n    y_pred_quantile = []\n    for sample in range(leaf_ids_test.shape[0]):\n        li = [\n            node_to_indices[tree][leaf_ids_test[sample][tree]]\n            for tree in range(leaf_ids_test.shape[1])\n        ]\n        # merge the list of indices into one\n        idx = [item for sublist in li for item in sublist]\n        # get the y_train for each corresponding id``\n        y_pred_quantile.append(y_train[idx])\n    # get the quatile preditions for each predicted sample\n    y_preds = [\n        [np.quantile(y_pred_quantile[i], quantile) for i in range(len(y_pred_quantile))]\n        for quantile in quantiles\n    ]\n    return y_preds\n\n\nrng = check_random_state(0)\n\ndollar_formatter = FuncFormatter(lambda x, p: \"$\" + format(int(x), \",\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the California Housing Prices dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "california = datasets.fetch_california_housing()\nn_samples = min(california.target.size, 1000)\nperm = rng.permutation(n_samples)\nX = california.data[perm]\ny = california.target[perm]\n\nrf = RandomForestRegressor(n_estimators=100, random_state=0)\n\nkf = KFold(n_splits=5)\nkf.get_n_splits(X)\n\ny_true = []\ny_pred = []\ny_pred_lower = []\ny_pred_upper = []\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test, y_train, y_test = (\n        X[train_index],\n        X[test_index],\n        y[train_index],\n        y[test_index],\n    )\n\n    rf.set_params(max_features=X_train.shape[1] // 3)\n\n    # Get predictions at 95% prediction intervals and median.\n    y_pred_i = get_quantile_prediction(rf, X_train, X_test, y_train, quantiles=[0.025, 0.5, 0.975])\n\n    y_true = np.concatenate((y_true, y_test))\n    y_pred = np.concatenate((y_pred, y_pred_i[1]))\n    y_pred_lower = np.concatenate((y_pred_lower, y_pred_i[0]))\n    y_pred_upper = np.concatenate((y_pred_upper, y_pred_i[2]))\n\n# Scale data to dollars.\ny_true *= 1e5\ny_pred *= 1e5\ny_pred_lower *= 1e5\ny_pred_upper *= 1e5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the results\nPlot the conditional median and prediction intervals.\nThe left plot shows the predicted  (conditional median) with the confidence intervals at 95%\nagainst the training data. The upper and lower bounds are indicated with the blue lines segments.\nThe right plot shows showed the same prediction sorted by the predicted value and centered at the\nhalfway point between the upper and lower bounds. This allows us to see the distribution of the\nconfidence intervals, which increases as the variance of the predicted value increases.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\ny_pred_interval = y_pred_upper - y_pred_lower\nsort_idx = np.argsort(y_pred)\ny_true = y_true[sort_idx]\ny_pred = y_pred[sort_idx]\ny_pred_lower = y_pred_lower[sort_idx]\ny_pred_upper = y_pred_upper[sort_idx]\ny_min = min(np.minimum(y_true, y_pred))\ny_max = max(np.maximum(y_true, y_pred))\ny_min = float(np.round((y_min / 10000) - 1, 0) * 10000)\ny_max = float(np.round((y_max / 10000) - 1, 0) * 10000)\n\nfor low, mid, upp in zip(y_pred_lower, y_pred, y_pred_upper):\n    ax1.plot([mid, mid], [low, upp], lw=4, c=\"#e0f2ff\")\n\nax1.plot(y_pred, y_true, c=\"#f2a619\", lw=0, marker=\".\", ms=5)\nax1.plot(y_pred, y_pred_lower, alpha=0.4, c=\"#006AFF\", lw=0, marker=\"_\", ms=4)\nax1.plot(y_pred, y_pred_upper, alpha=0.4, c=\"#006AFF\", lw=0, marker=\"_\", ms=4)\nax1.plot([y_min, y_max], [y_min, y_max], ls=\"--\", lw=1, c=\"grey\")\nax1.grid(axis=\"x\", color=\"0.95\")\nax1.grid(axis=\"y\", color=\"0.95\")\nax1.xaxis.set_major_formatter(dollar_formatter)\nax1.yaxis.set_major_formatter(dollar_formatter)\nax1.set_xlim(y_min, y_max)\nax1.set_ylim(y_min, y_max)\nax1.set_xlabel(\"Fitted Values (Conditional Median)\")\nax1.set_ylabel(\"Observed Values\")\n\ny_pred_interval = y_pred_upper - y_pred_lower\nsort_idx = np.argsort(y_pred_interval)\ny_true = y_true[sort_idx]\ny_pred_lower = y_pred_lower[sort_idx]\ny_pred_upper = y_pred_upper[sort_idx]\n\n# Center data, with the mean of the prediction interval at 0.\nmean = (y_pred_lower + y_pred_upper) / 2\ny_true -= mean\ny_pred_lower -= mean\ny_pred_upper -= mean\n\nax2.plot(y_true, c=\"#f2a619\", lw=0, marker=\".\", ms=5)\nax2.fill_between(\n    np.arange(len(y_pred_upper)),\n    y_pred_lower,\n    y_pred_upper,\n    alpha=0.8,\n    color=\"#e0f2ff\",\n)\nax2.plot(np.arange(n_samples), y_pred_lower, alpha=0.8, c=\"#006aff\", lw=2)\nax2.plot(np.arange(n_samples), y_pred_upper, alpha=0.8, c=\"#006aff\", lw=2)\nax2.grid(axis=\"x\", color=\"0.95\")\nax2.grid(axis=\"y\", color=\"0.95\")\nax2.yaxis.set_major_formatter(dollar_formatter)\nax2.set_xlim([0, n_samples])\nax2.set_xlabel(\"Ordered Samples\")\nax2.set_ylabel(\"Observed Values and Prediction Intervals\")\n\nplt.subplots_adjust(top=0.15)\nfig.tight_layout(pad=3)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}